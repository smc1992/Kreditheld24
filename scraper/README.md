# Kreditheld24 Zinssatz-Scraper

Ein automatisierter Service zum Sammeln aktueller ZinssÃ¤tze von verschiedenen Kreditvergleichsportalen.

## Features

- ğŸ• **Automatische tÃ¤gliche Updates** um 6:00 Uhr
- ğŸ”’ **Sichere API** mit Token-Authentifizierung
- ğŸ“Š **Monitoring und Logging** aller Scraping-AktivitÃ¤ten
- ğŸ³ **Docker-ready** fÃ¼r einfache Deployment
- ğŸ”„ **Retry-Mechanismen** bei Fehlern
- ğŸ“ˆ **Health Checks** fÃ¼r Ãœberwachung

## Architektur

```
scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Hauptserver
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â””â”€â”€ rateScraper.ts    # Scraping-Logik
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ rateStorage.ts    # Datenbank-Integration
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ auth.ts           # Authentifizierung
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.ts         # Logging
â”œâ”€â”€ Dockerfile                # Container-Konfiguration
â”œâ”€â”€ package.json             # Dependencies
â””â”€â”€ .env.example             # Umgebungsvariablen
```

## Installation

### Lokale Entwicklung

```bash
cd scraper
npm install
cp .env.example .env
# Konfiguriere .env Datei
npm run dev
```

### Docker Build

```bash
docker build -t kreditheld24-scraper .
docker run -p 3002:3002 --env-file .env kreditheld24-scraper
```

### Mit Docker Compose

```bash
# Im Hauptverzeichnis
docker-compose up scraper
```

## Konfiguration

### Umgebungsvariablen

```env
# Server
NODE_ENV=production
PORT=3002
LOG_LEVEL=info

# Datenbank
DATABASE_URL=postgresql://user:pass@host:5432/db

# Authentifizierung
CRON_SECRET=your-secret-key

# Scraping
SCRAPING_DELAY=30000
MAX_RETRIES=3
TIMEOUT=60000

# Cron Schedule
CRON_SCHEDULE=0 6 * * *
TIMEZONE=Europe/Berlin
```

## API Endpoints

### Health Check
```http
GET /health
```

Response:
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "service": "kreditheld24-scraper"
}
```

### Manuelles Scraping
```http
POST /api/scrape
Authorization: Bearer YOUR_CRON_SECRET
```

Response:
```json
{
  "success": true,
  "timestamp": "2024-01-15T10:30:00.000Z",
  "results": [
    {
      "source": "check24",
      "success": true,
      "rateCount": 15,
      "error": null
    }
  ]
}
```

### Status Abfrage
```http
GET /api/status
```

## Coolify Integration

### Service-Konfiguration

1. **Neuer Service** in Coolify erstellen
2. **Git Repository** verbinden
3. **Build Path** auf `./scraper` setzen
4. **Port** auf `3002` konfigurieren
5. **Environment Variables** setzen

### Environment Variables in Coolify

```env
NODE_ENV=production
PORT=3002
DATABASE_URL=postgresql://kreditheld:${DB_PASSWORD}@postgres:5432/kreditheld24
CRON_SECRET=${CRON_SECRET}
CRON_SCHEDULE=0 6 * * *
TIMEZONE=Europe/Berlin
```

### Service Dependencies

- **PostgreSQL** (fÃ¼r Datenspeicherung)
- **Redis** (optional, fÃ¼r Caching)
- **Frontend** (fÃ¼r API-Integration)

## Monitoring

### Logs

```bash
# Container Logs
docker logs kreditheld24-scraper

# Log-Dateien
tail -f scraper/logs/combined.log
tail -f scraper/logs/error.log
```

### Health Checks

```bash
# Docker Health Check
docker inspect --format='{{.State.Health.Status}}' kreditheld24-scraper

# Manual Health Check
curl http://localhost:3002/health
```

### Metriken

- **Scraping-Erfolgsrate** pro Quelle
- **Durchschnittliche Scraping-Dauer**
- **Anzahl gesammelter ZinssÃ¤tze**
- **Fehlerrate und -typen**

## Scraping-Quellen

### Aktuell implementiert (Demo)

- **Check24** (simuliert)
- **Verivox** (simuliert)
- **Smava** (simuliert)

### Geplante Erweiterungen

- **ING Bank** (direkte Website)
- **DKB** (direkte Website)
- **Commerzbank** (direkte Website)
- **Santander** (direkte Website)

## Sicherheit

### Best Practices

- **Rate Limiting** zwischen Requests
- **User-Agent Rotation**
- **Proxy-UnterstÃ¼tzung** (optional)
- **robots.txt Respektierung**
- **Fehler-Handling** bei Blockierungen

### Rechtliche Aspekte

- **Terms of Service** beachten
- **Moderate Frequenz** (1x tÃ¤glich)
- **Keine Ã¼bermÃ¤ÃŸige Server-Belastung**
- **Transparente User-Agents**

## Troubleshooting

### HÃ¤ufige Probleme

**Scraping schlÃ¤gt fehl:**
```bash
# Logs prÃ¼fen
docker logs kreditheld24-scraper

# Manuell testen
curl -X POST http://localhost:3002/api/scrape \
  -H "Authorization: Bearer YOUR_SECRET"
```

**Datenbank-Verbindung:**
```bash
# PostgreSQL Verbindung testen
psql $DATABASE_URL -c "SELECT 1;"
```

**Cron-Jobs laufen nicht:**
```bash
# Environment prÃ¼fen
echo $NODE_ENV
echo $CRON_SCHEDULE
```

## Entwicklung

### Neue Scraper hinzufÃ¼gen

1. **Scraper-Funktion** in `scrapers/rateScraper.ts` erstellen
2. **Tests** schreiben
3. **Error-Handling** implementieren
4. **Logging** hinzufÃ¼gen

### Testing

```bash
# Unit Tests
npm test

# Integration Tests
npm run test:integration

# Manual Testing
npm run scrape
```

## Deployment

### Coolify Deployment

1. **Git Push** â†’ Automatisches Build
2. **Health Check** â†’ Service-VerfÃ¼gbarkeit
3. **Logs** â†’ Monitoring in Coolify
4. **Rollback** â†’ Bei Problemen

### Produktions-Checkliste

- [ ] Environment Variables gesetzt
- [ ] Datenbank-Schema erstellt
- [ ] Health Checks funktionieren
- [ ] Cron-Jobs konfiguriert
- [ ] Monitoring eingerichtet
- [ ] Backup-Strategie definiert

## Support

Bei Problemen:

1. **Logs prÃ¼fen** (`/logs/` Verzeichnis)
2. **Health Check** aufrufen (`/health`)
3. **Manuelle Scraping** testen (`/api/scrape`)
4. **Datenbank-Verbindung** prÃ¼fen
5. **Environment Variables** validieren